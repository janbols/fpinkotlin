= 7 Purely functional parallelism
:toc:
:icons: font
:url-quickref: https://livebook.manning.com/book/functional-programming-in-kotlin/chapter-7/

{url-quickref}[See chapter online chapter].

Build a purely functional library to create parallel and asynchronous computations.

What you should take away from this chapter is not how to write a library for purely functional parallelism, but _how to approach the problem of designing a purely functional library_.

*Separating the concern of describing a computation from actually running it*

Doel: develop a combinator, `parMap`, that lets us easily apply a function f to every element in a collection simultaneously:
[source, kotlin]
----
val outputList = parMap(inputList, f)
----

> We’ll introduce algebraic reasoning and demonstrate that an API can be described by an algebra that obeys specific laws.


== 7.1 Choosing data types and functions

We’d like to be able to “create parallel computations,” but what does that mean exactly?

vb: summing a list of integers

[source, kotlin]
----
fun sum(ints: List<Int>): Int =
    ints.foldLeft(0) { a, b -> a + b }
----

Instead of folding sequentially, we could use a divide-and-conquer algorithm as shown in the following listing.
[source, kotlin]
----
fun sum(ints: List<Int>): Int =
    if (ints.size <= 1)
        ints.firstOption().getOrElse { 0 }
    else {
        val (l, r) = ints.splitAt(ints.size / 2)
        sum(l) + sum(r)
    }
----

-> this implementation can be parallelized with the two halves being summed in parallel.


NOTE: Summing integers in practice is so fast that parallelization imposes more overhead than it saves. But simple examples like this are the most helpful to consider when designing a functional library.

=== 7.1.1 A data type for parallel computations

`sum(l) + sum(r)`

-> any data type we might choose to represent our parallel computation needs to contain a result.

-> also require a way to extract the result.

Iteration 1:
[source, kotlin]
----
class Par<A>(val get: A)

fun <A> unit(a: () -> A): Par<A> = Par(a())

fun <A> get(a: Par<A>): A = a.get
----

Revisit sum:

[source, kotlin]
----
fun sum(ints: List<Int>): Int =
    if (ints.size <= 1)
        ints.firstOption().getOrElse { 0 }
    else {
        val (l, r) = ints.splitAt(ints.size / 2)
        val sumL: Par<Int> = unit { sum(l) }
        val sumR: Par<Int> = unit { sum(r) }
        sumL.get + sumR.get
    }
----

#Should `unit` begin evaluating its argument immediately in a separate _logical_ thread, or it could simply defer evaluation of its argument until `get` is called?#

-> If we want to obtain any degree of parallelism, we require that `unit` begin evaluating its argument concurrently and immediately return without blocking. Why?

[%collapsible]
====
Function arguments in Kotlin are *strictly* evaluated from left to right, so if `unit` delays execution until `get` is called, we will spawn the parallel computation and wait for it to finish before spawning the second parallel computation. This means the computation is effectively sequential!
====


#If `unit` begins evaluating its argument concurrently, then calling `get` is responsible for breaking referential transparency.# We can see this by replacing `sumL` and `sumR` with their definitions—if we do so, we still get the same result, but our program is no longer parallel.

[source, kotlin]
----
unit { sum(l) }.get + unit { sum(r) }.get
----

We can see that `unit` has a definite side effect but only in conjunction with `get`. So we should avoid calling `get`, or at least delay calling it until the very end.

> Before we continue, let’s reflect on what we’ve done: First, we conjured up a simple, almost trivial example. Next, we explored this example to uncover a design choice. Then, via some experimentation, we discovered an intriguing consequence of one option and, in the process, learned something fundamental about the nature of our problem domain! The overall design process is a series of small adventures. You don’t need a special license to do such exploration, and you certainly don’t need to be an expert in functional programming. Just dive in and see what you can find!

=== 7.1.2 Combining parallel computations to ensure concurrency

How to avoid the pitfall mentioned earlier of combining `unit` and `get`.

[%collapsible]
====
If we don’t call `get`, that implies that our sum function must return a `Par<Int>`

[source, kotlin]
----
fun sum(ints: List<Int>): Par<Int> =
    if (ints.size <= 1)
        unit { ints.firstOption().getOrElse { 0 } }
    else {
        val (l, r) = ints.splitAt(ints.size / 2)
        map2(sum(l), sum(r)) { lx: Int, rx: Int -> lx + rx }
    }
----

====


The higher-order function `map2` is a new function for combining the result of two parallel computations. *What is its signature?*

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex1/listing.kt[]

Observe that we’re no longer calling `unit` in the recursive case, and it isn’t clear whether `unit` should accept its argument lazily anymore. In this example, accepting the lazy argument doesn’t seem to provide many benefits, but perhaps this isn’t always the case. Let’s come back to this question later.

#Should `map2` take its arguments lazily?#

What happens if `map2` is strict in both arguments as we evaluate `sum(listOf(1, 2, 3, 4))`.

[source, kotlin]
----
sum(listOf(1, 2, 3, 4))

map2(
    sum(listOf(1, 2)),
    sum(listOf(3, 4))
) { i: Int, j: Int -> i + j }

map2(
    map2(
        sum(listOf(1)),
        sum(listOf(2))
    ) { i: Int, j: Int -> i + j },
    sum(listOf(3, 4))
) { i: Int, j: Int -> i + j }

map2(
    map2(
        unit { 1 },
        unit { 2 }
    ) { i: Int, j: Int -> i + j },
    sum(listOf(3, 4))
) { i: Int, j: Int -> i + j }

map2(
    map2(
        unit { 1 },
        unit { 2 }
    ) { i: Int, j: Int -> i + j },
    map2(
        sum(listOf(3)),
        sum(listOf(4))
    ) { i: Int, j: Int -> i + j }
) { i: Int, j: Int -> i + j }

----

-> because `map2` is strict, and Kotlin evaluates arguments left to right

-> If `map2` doesn’t begin evaluation immediately, this implies that a `Par` value is merely constructing a _description_ of what needs to be computed in parallel. Nothing actually occurs until we _evaluate_ this description, perhaps by using a `get`-like function.

-> seems that we should make `map2` lazy so it begins the immediate execution of both sides in parallel

=== 7.1.3 Marking computations to be forked explicitly

#Is it always the case that we want to evaluate the two arguments to `map2` in parallel?# Probably not.

[source, kotlin]
----
map2(
    unit { 1 },
    unit { 2 }
) { i: Int, j: Int -> i + j }
----

We know that the two computations we’re combining will execute so quickly that there isn’t any point in spawning a new logical thread to evaluate them. But our API doesn’t give us any way to provide this sort of information.

Our current API is very _inexplicit_ about when computations are forked off the main thread into a new thread process. The programmer doesn’t get to specify where this forking should occur.

[source, kotlin]
----
fun <A> fork(a: () -> Par<A>): Par<A> = TODO()
----

Revisit Sum:

[source, kotlin]
----
fun sum(ints: List<Int>): Par<Int> =
    if (ints.size <= 1)
        unit { ints.firstOption().getOrElse { 0 } }
    else {
        val (l, r) = ints.splitAt(ints.size / 2)
        map2(
            fork { sum(l) },
            fork { sum(r) }
        ) { lx: Int, rx: Int -> lx + rx }
    }
----

With `fork`, we can now make `map2` strict, leaving it up to the programmer to wrap arguments if they wish.

-> it puts the parallelism explicitly under programmer control.

Keeping 2 concerns separate:

* some way to indicate that the results of the two parallel tasks should be combined
* choice of whether a particular task should be performed asynchronously

#Should `unit` be strict or lazy?# With `fork`, we can now make `unit` strict without any loss of expressiveness. A non-strict version of it, let’s call it `lazyUnit`, can be implemented using `unit` and `fork`.

[source, kotlin]
----
fun <A> unit(a: A): Par<A> = Par(a)

fun <A> lazyUnit(a: () -> A): Par<A> =
    fork { unit(a()) }
----

* `lazyUnit` -> *derived* combinator
* `unit` -> *primitive* combinator


We want `fork` to signal that its argument is evaluated in a separate logical thread.

#Should it begin doing so _immediately_ upon being called or hold on to its argument to be evaluated in a logical thread _later_ when the computation is forced using something like `get`. Should evaluation be _eager_ or _lazy_?#

Suppose fork begins evaluating its argument _immediately_ in parallel.

-> the implementation must clearly know something about creating threads or submitting tasks to some sort of thread pool.

-> implies that the thread pool or whatever resource must be globally accessible and properly initialized wherever we want to call fork.

-> we lose the ability to control the parallelism strategy used for different parts of our program

We can imagine how it would be helpful to have more fine-grained control over what implementations are used and in what context.

-> much more appropriate to give `get` the responsibility of creating threads and submitting execution tasks.

`fork` just takes an unevaluated `Par` and “marks” it for concurrent evaluation.

-> Par itself doesn’t need to know how to actually implement the parallelism. It’s more a _description_ of a parallel computation that is interpreted at a later time by something like the `get` function.

=> Shift from before:

* Before we were considering `Par` to be a container of a value that we could simply `get` when it becomes available.
* Now it’s more of a first-class program that we can `run`.

-> let’s rename our `get` function to `run`:


[source, kotlin]
----
fun <A> run(a: Par<A>): A = TODO()
----

-> `Par` is now just a pure data structure, `run` has to have some means of implementing the parallelism, whether it spawns new threads, delegates tasks to a thread pool, or uses another mechanism.

== 7.2 Picking a representation

[source, kotlin]
----
fun <A> unit(a: A): Par<A>

fun <A, B, C> map2(
    a: Par<A>,
    b: Par<B>,
    f: (A, B) -> C
): Par<C>

fun <A> fork(a: () -> Par<A>): Par<A>

fun <A> lazyUnit(a: () -> A): Par<A>

fun <A> run(a: Par<A>): A
----


> Try to come up with a representation for `Par` that makes it possible to implement the functions of our API.

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex2/listing.kt[]




Let’s see if we can come up with a representation together. We know that run somehow needs to execute asynchronous tasks.

[source, kotlin]
----
interface Callable<A> {
    fun call(): A
}

interface Future<A> {
    fun get(): A
    fun get(timeout: Long, timeUnit: TimeUnit): A
    fun cancel(evenIfRunning: Boolean): Boolean
    fun isDone(): Boolean
    fun isCancelled(): Boolean
}

interface ExecutorService {
    fun <A> submit(c: Callable<A>): Future<A>
}
----




Now try to imagine how we could modify `run` in our `Par` data type if we had access to an instance of the `ExecutorService`:

[source, kotlin]
----
fun <A> run(es: ExecutorService, a: Par<A>): A = TODO()
----

Turn `Par<A>` into a type alias of a function such as `(ExecutorService) -> A`. If we invoked this function with an instance of an ExecutorService, it would produce something of type A, making the implementation trivial. We can improve this further by giving the caller of run the ability to defer how long to wait for computation or cancel it altogether.

[source, kotlin]
----
typealias Par<A> = (ExecutorService) -> Future<A>

fun <A> run(es: ExecutorService, a: Par<A>): Future<A> = a(es)
----

-> Since `Par` is now represented by a function that needs an `ExecutorService`, the creation of the `Future` doesn’t actually happen until this `ExecutorService` is provided.


== 7.3 Refining the API with the end user in mind

=> We devote this section to exploring and refining our API.

Pars reiterated:

[source, kotlin]
----
object Pars {
    fun <A> unit(a: A): Par<A> =
        { es: ExecutorService -> UnitFuture(a) }

    data class UnitFuture<A>(val a: A) : Future<A> {

        override fun get(): A = a

        override fun get(timeout: Long, timeUnit: TimeUnit): A = a

        override fun cancel(evenIfRunning: Boolean): Boolean = false

        override fun isDone(): Boolean = true

        override fun isCancelled(): Boolean = false
    }

    fun <A, B, C> map2(
        a: Par<A>,
        b: Par<B>,
        f: (A, B) -> C
    ): Par<C> =
        { es: ExecutorService ->
            val af: Future<A> = a(es)
            val bf: Future<B> = b(es)
            UnitFuture(f(af.get(), bf.get()))
        }

    fun <A> fork(
        a: () -> Par<A>
    ): Par<A> =
        { es: ExecutorService ->
            es.submit(Callable<A> { a()(es).get() })
        }
}
----

issues:

* `unit`: returns a `UnitFuture`, a simple implementation of `Future`
* `map2`: f wordt niet in aparte thread uitgevoerd want we hebben ervoor gekozen om dit te laten uitdrukker door `fork`. We kunnen altijd `map2` wrappen in `fork`.
* `map2`: does not respect timeouts. To respect timeouts, we’d need a new `Future` implementation that recorded the amount of time spent evaluating `af` and then subtracted that time from the available time allocated for evaluating `bf`.
* `fork`: the outer Callable will block waiting for the “inner” task to complete

> An important point to make is that even though the methods on `Future` rely on side effects, our entire `Par` API remains *pure*. Only after the user calls `run` and the implementation receives an `ExecutorService` do we expose the `Future`’s machinery. Our users are therefore programming to a pure interface with an implementation that relies on effects. But _since our API remains pure, these effects aren’t side effects_.


Fix the implementation of map2 so that it respects the contract of timeouts on Future.

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex3/listing.kt[]

NOTE: xref:../../../test/kotlin/chapter7/solutions/ex3/listing.kt[]

=== asyncF

> using `lazyUnit`, write a function to convert any function (A) -> B to one that evaluates its result asynchronously.

[source, kotlin]
----
fun <A, B> asyncF(f: (A) -> B): (A) -> Par<B> =
----

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex4/listing.kt[]

=== sortPar

> Suppose we have a `Par<List<Int>>` representing a parallel computation that produces a `List<Int>`, and we’d like to convert this to a `Par<List<Int>>` with a *sorted* result:

[source, kotlin]
----
fun sortPar(parList: Par<List<Int>>): Par<List<Int>> = TODO()
----

[%collapsible]
====
We could `run` the `Par`, sort the resulting list, and repackage it in a `Par` with `unit`. But we want to *avoid calling run*.

The only other combinator we have that allows us to manipulate the value of a `Par` in any way is `map2`.

So if we pass parList to one side of `map2`, we’ll be able to gain access to the `List` inside and sort it. And we can pass whatever we want to the other side of `map2`, so let’s just pass a `Unit`:

[source, kotlin]
----
fun sortPar(parList: Par<List<Int>>): Par<List<Int>> =
    map2(parList, unit(Unit)) { a, _ -> a.sorted() }
----

====

=== map

=> generalize: We can “lift” any function of type `(A) -> B` to become a function that takes `Par<A>` and returns `Par<B>`

[source, kotlin]
----
fun <A, B> map(pa: Par<A>, f: (A) -> B): Par<B> =
    map2(pa, unit(Unit), { a, _ -> f(a) })
----

sortPar:

[source, kotlin]
----
fun sortPar(parList: Par<List<Int>>): Par<List<Int>> =
    map(parList) { it.sorted() }
----

=> The fact that we can implement `map` in terms of `map2` but not the other way around shows that _`map2` is strictly more powerful than `map`_.

> This sort of thing happens a lot when we’re designing libraries—often, a function that seems to be primitive turns out to be expressible using a more powerful primitive.

=== parMap

Could we map over a list in parallel? Unlike `map2`, which combines two parallel computations, `parMap` needs to combine N parallel computations. It seems like this should somehow be expressible:

[source, kotlin]
----
fun <A, B> parMap(
    ps: List<A>,
    f: (A) -> B
): Par<List<B>> = TODO()
----

First try:

[source, kotlin]
----
fun <A, B> parMap(
    ps: List<A>,
    f: (A) -> B
): Par<List<B>> {
    val fbs: List<Par<B>> = ps.map(asyncF(f))
    TODO()
}
----

-> we need a way to convert our `List<Par<B>>` to the `Par<List<B>>`

=== Sequence

> Write this function, called sequence. No additional primitives are required. Do not call run.

[source, kotlin]
----
fun <A> sequence(ps: List<Par<A>>): Par<List<A>> =
----

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex5/listing.kt[]

NOTE: xref:../../../test/kotlin/chapter7/solutions/ex5/listing.kt[]

`parMap` 2nd try:

[source, kotlin]
----
fun <A, B> parMap(
    ps: List<A>,
    f: (A) -> B
): Par<List<B>> = fork {
    val fbs: List<Par<B>> = ps.map(asyncF(f))
    sequence(fbs)
}
----


NOTE: we’ve wrapped our implementation in a call to `fork`. With this implementation, `parMap` will return immediately, even for an enormous input list. When we later call `run`, it will `fork` a single asynchronous computation, which itself spawns N parallel computations and then waits for these computations to finish, collecting their results into a list.

=== parFilter

> Implement parFilter, which filters elements of a list in parallel.

[source, kotlin]
----
fun <A> parFilter(
    sa: List<A>,
    f: (A) -> Boolean
): Par<List<A>> =
----

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex6/listing.kt[]

Vrijblijvend:

* Is there a more general version of the parallel summation function we wrote at the beginning of this chapter? Try using it to find the maximum value of a List in parallel.
* Write a function that takes a list of paragraphs (a `List<String>`) and returns the total number of words across all paragraphs in parallel. Generalize this function as much as possible.
* Implement `map3`, `map4`, and `map5` in terms of `map2`.


== 7.4 Reasoning about the API in terms of algebraic equations

> Algebra: We do mean algebra in the mathematical sense of one or more sets, together with a collection of functions operating on objects of these sets and a set of axioms. Axioms are statements assumed true, from which we can derive other theorems that must also be true. In our case, the sets are particular types like `Par<A>` and `List<Par<A>>`, and the functions are operations like `map2`, `unit`, and `sequence`.

=== 7.4.1 The law of mapping

> choosing laws has profound consequences: it places constraints on what the operations mean, determines the possible implementation choices, and affects what other properties can be true.

example:

[source, kotlin]
----
map(unit(1)) { it + 1 } == unit(2)
----

-> mapping over `unit(1)` with the `{ it + 1 }` function is in some sense equivalent to `unit(2)`

-> Equivalent: two `Par` objects are *equivalent* if for any valid `ExecutorService` argument, their `Future` results have the same value.

-> Just as we can generalize functions, we can generalize laws.

[source, kotlin]
----
map(unit(x), f) == unit(f(x))
----

=> this should hold true for any choice of `x` and `f`

=> This places some constraints on our implementation: it can’t make any assumptions or change behavior based on the values it receives.

-> substitute `f` for the identity-function: `fun <A> id(a: A): A = a`

We can now simplify both sides of the equation and get a new law that’s less complicated, much like the substitution one might do when solving an algebraic equation.

[source, kotlin]
----
val x = 1
val y = unit(x)
val f = { a: Int -> a + 1 }
val id = { a: Int -> a }

map(unit(x), f) == unit(f(x))
map(unit(x), id) == unit(id(x))
map(unit(x), id) == unit(x)
map(y, id) == y
----

[source, kotlin]
----
map(y, id) == y
----

Let’s think about what map _can’t_ do:

* It can’t throw an exception and crash the computation before applying the function to the result.
* All map can do is apply the function f to the result of y, which in turn leaves y unaffected when that function is id.

> We say that map is required to be *structure preserving* in that it doesn’t alter the structure of the parallel computation—only the value *“inside”* the computation.

=== 7.4.2 The law of forking

`fork` should not affect the result of parallel computation:

[source, kotlin]
----
fork { x } == x
----

=> this simple property places strong constraints on our implementation of fork.

==== Breaking the law: A subtle bug

We’re expecting that fork(x) == x for all choices of x and any choice of ExecutorService.

Assertion about equality:
[source, kotlin]
----
infix fun <A> Par<A>.shouldBe(other: Par<A>) = { es: ExecutorService ->
    if (this(es).get() != other(es).get())
        throw AssertionError("Par instances not equal")
}
----

Take a look through the various static methods in Executors to get a feel for the different implementations of ExecutorService that exist. Then, before continuing, go back and revisit your implementation of fork and try to find a counterexample or convince yourself that the law holds for your implementation.


http://mng.bz/Q2B1

NOTE: Implementation of fork:

[source, kotlin]
----
fun <A> fork(a: () -> Par<A>): Par<A> =
    { es ->
        es.submit(Callable<A> {
            a()(es).get()
        })
    }

----


[%collapsible]
====

[source, kotlin]
----
val es = Executors.newFixedThreadPool(1)

val a: Par<Int> = lazyUnit { 42 + 1 }
val b: Par<Int> = fork { a }
(a shouldBe b)(es)
----

====

NOTE: Why laws about code and proofs are important? Using FP, it’s easy and expected to factor out standard functionality into generic, reusable components that can be composed. Side effects hurt compositionality, but more generally, any hidden nondeterministic behavior that prevents us from treating our components as black boxes makes composition difficult or impossible. It means we can confidently treat all the objects of our APIs as black boxes.



> Show that any fixed-size thread pool can be made to deadlock given this implementation of fork.

[%collapsible]
====
For a thread pool of size 2, `fork(fork(fork(x)))` will deadlock, and so on. Another, perhaps more interesting, example is `fork(map2(fork(x), fork(y)))`. In this case, the outer task is submitted first and occupies a thread waiting for both `fork(x)` and `fork(y)`. The `fork(x)` and `fork(y)` tasks are submitted and run in parallel, except that only one thread is available, resulting in deadlock.
====


When you find counterexamples like this, you have two choices:

1. you can try to fix your implementation such that the law holds,
2. you can refine your law to more explicitly state the conditions under which it holds: stipulate that you require thread pools that can grow unbounded


Original:
[source, kotlin]
----
fun <A> fork(a: () -> Par<A>): Par<A> =
    { es ->
        es.submit(Callable<A> {
            a()(es).get()
        })
    }
----

Fix for fixed thread pools:
[source, kotlin]
----
fun <A> fork(pa: () -> Par<A>): Par<A> =
    { es -> pa()(es) }
----



Problem: doesn't fork.

-> still a useful combinator since it lets us delay the instantiation of computation until it’s needed. Let’s give it a new name, delay:

[source, kotlin]
----
fun <A> delay(pa: () -> Par<A>): Par<A> =
    { es -> pa()(es) }
----


What we’d really like to do is run arbitrary computations over fixed-size thread pools. To do that, we’ll need to pick a different representation of Par.

=== 7.4.3 Using actors for a non-blocking implementation

The essential problem with the current representation is that we can’t get a value out of a `Future` without the current thread blocking on its `get` method. A representation of `Par` that doesn’t leak resources this way has to be non-blocking in the sense that the implementations of `fork` and `map2` must never call a method that blocks the current thread like `Future.get` does.

Writing a correct implementation can be challenging. Fortunately, we have laws to test our implementation, and we only have to get it right once. After that, our library users can enjoy a composable and abstract API that does the right thing every time.


==== Rethinking Par as non-blocking by registering a callback

Instead of turning `Par` into a `java.util.concurrent.Future`, which only allows us to `get` a value through a blocking call, we’ll introduce our own version of Future. Our version can register a *callback* (=*continuation*) that will be invoked when the result is ready.

[source, kotlin]
----
abstract class Future<A> {
    internal abstract fun invoke(cb: (A) -> Unit)
}

typealias Par<A> = (ExecutorService) -> Future<A>
----

==== unit
[source, kotlin]
----
fun <A> unit(a: A): Par<A> =
    { es: ExecutorService ->
        object : Future<A>() {
            override fun invoke(cb: (A) -> Unit) = cb(a)
         }
    }

----

==== run

[source, kotlin]
----
fun <A> run(es: ExecutorService, pa: Par<A>): A {
    val ref = AtomicReference<A>()
    val latch = CountDownLatch(1)
    pa(es).invoke { a: A ->
        ref.set(a)
        latch.countDown()
    }
    latch.await()
    return ref.get()
}
----


In our current implementation, `run` blocks the calling thread while waiting for the `latch` to be released. In fact, it isn’t possible to write an implementation of `run` that doesn’t block. Our method has to wait for a value of `A` to materialize before it can return anything.

For this reason, we want users of our API to avoid calling `run` until they definitely want to wait for a result. We could even go so far as to remove `run` from our API and expose the `invoke` method on Par so that users can register asynchronous callbacks. That would certainly be a valid design choice, but we’ll leave our API as it is for now.

Alternative using *CompletableFuture*:


[source, kotlin]
----
fun <A> run2(es: ExecutorService, pa: Par<A>): A {
    val ref = CompletableFuture<A>()
    pa(es).invoke { a: A ->
        ref.complete(a)
    }
    return ref.get()
}
----


`CountDownLatch` is no longer necessary since blocking the thread is managed by the `CompletableFuture`.

==== fork

[source, kotlin]
----
fun <A> fork(a: () -> Par<A>): Par<A> =
    { es: ExecutorService ->
        object : Future<A>() {
            override fun invoke(cb: (A) -> Unit) =
                eval(es) { a()(es).invoke(cb) }
        }
    }

fun eval(es: ExecutorService, r: () -> Unit) {
    es.submit(Callable { r() })
}

----

When the `Future` returned by `fork` receives its continuation `cb`, it forks off a task to evaluate the lazy argument `a`. Once the argument has been evaluated and called to produce a `Future<A>`, we register `cb` for invocation after `Future` has its resulting `A`.

==== map2

[source, kotlin]
----
fun <A, B, C> map2(pa: Par<A>, pb: Par<B>, f: (A, B) -> C): Par<C>
----

Here, a non-blocking implementation is considerably trickier. Conceptually, we’d like `map2` to run both `Par` arguments in parallel. When both results have arrived, we want to invoke `f` and then pass the resulting `C` to the continuation.

==== A brief detour demonstrating the use of actors

An *actor* is a concurrent process that doesn’t constantly occupy a thread. Instead, it only occupies a thread when it receives a message. Significantly, although multiple threads may concurrently send messages to an actor, the actor processes only one message at a time, queueing other messages for subsequent processing. This makes actors useful as concurrency primitives when writing tricky code that must be accessed by multiple threads and that would otherwise be prone to race conditions or deadlocks.

[source, kotlin]
----
val es: ExecutorService = Executors.newFixedThreadPool(4)
val s = Strategy.from(es)
val echoer = Actor<String>(s) {
    println("got message: $it")
}
----

[source, kotlin]
----
echoer.send("hello")
//got message: hello

echoer.send("goodbye")
//got message: goodbye

echoer.send("You're just repeating everything I say, aren't you?")
//got message: You're just repeating everything I say, aren't you?
----

NOTE: zie xref:sec4_4/actor.kt[]]

==== Implementing map2 via actors

[source, kotlin]
----
fun <A, B, C> map2(pa: Par<A>, pb: Par<B>, f: (A, B) -> C): Par<C> =
    { es: ExecutorService ->
        object : Future<C>() {
            override fun invoke(cb: (C) -> Unit) {
                val ar = AtomicReference<Option<A>>(None)
                val br = AtomicReference<Option<B>>(None)
                val combiner =
                    Actor<Either<A, B>>(Strategy.from(es)) { eab ->
                        when (eab) {
                            is Left<A> ->
                                br.get().fold(
                                    { ar.set(Some(eab.a)) },
                                    { b -> eval(es) { cb(f(eab.a, b)) } }
                                )
                            is Right<B> ->
                                ar.get().fold(
                                    { br.set(Some(eab.b)) },
                                    { a -> eval(es) { cb(f(a, eab.b)) } }
                                )
                        }
                    }
                pa(es).invoke { a: A -> combiner.send(Left(a)) }
                pb(es).invoke { b: B -> combiner.send(Right(b)) }
            }
        }
    }
----




Given these implementations, we should now be able to run Par values of arbitrary complexity without having to worry about running out of threads, even if the actors only have access to a single JVM thread.

[source, kotlin]
----
val p: (ExecutorService) -> Future<List<Double>> =
    parMap((1..100000).toList()) { sqrt(it.toDouble()) }

val x: List<Double> =
    run(Executors.newFixedThreadPool(2), p)

println(x)
----

This calls fork about 100,000 times, starting that many actors to combine these values two at a time. Thanks to our non-blocking Actor implementation, we don’t need 100,000 JVM threads to perform this processing, but we manage to do it with a fixed thread pool size of 2! And thus we have proved that our law of forking holds for fixed-size thread pools.




In general, there are multiple approaches you can consider when choosing laws for your API.

* You can think about your conceptual model and reason from there to postulate laws that should hold true.
* You can also just invent laws you think might be helpful or instructive (like we did with our fork law) and see if it’s possible and even sensible to ensure that they hold for your model.
* And finally, you can look at your implementation and come up with laws you expect to hold based on that.

== 7.5 Refining combinators to their most general form

... it’s a good idea to see if you can refine the combinator you need to its most _general_ form.

=== Choice

Suppose we want a function to choose between two forking computations based on the result of an initial computation:

[source, kotlin]
----
fun <A> choice(cond: Par<Boolean>, t: Par<A>, f: Par<A>): Par<A>
----


This constructs a computation that proceeds with `t` if `cond` results in true, or `f` if `cond` results in false.

Here’s a simple blocking implementation:
[source, kotlin]
----
fun <A> choice(cond: Par<Boolean>, t: Par<A>, f: Par<A>): Par<A> =
    { es: ExecutorService ->
        when (run(es, cond).get()) {
            true -> run(es, t)
            false -> run(es, f)
        }
    }
----

Why just two? If it’s helpful to choose between two parallel computations based on the results of a first, it should certainly be helpful to choose among N computations:

[source, kotlin]
----
fun <A> choiceN(n: Par<Int>, choices: List<Par<A>>): Par<A>
----

Let’s say that `choiceN` runs `n` and then uses that to select a parallel computation from `choices`. This is a bit more general than `choice`.




Implement `choiceN`, followed by `choice` in terms of `choiceN`.

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex10/listing.kt[]


We’ve _generalized_ our original combinator `choice` to `choiceN`, which can now express `choice` as well as other use cases not supported by `choice`.

The choice of `List` seems overly specific. Why does it matter what sort of container we have? What if instead of a `List`, we have a `Map` of computations?



Implement a combinator called `choiceMap` that accepts a `Map<K, Par<V>>` as container.

[source, kotlin]
----
fun <K, V> choiceMap(
    key: Par<K>,
    choices: Map<K, Par<V>>
): Par<V> =
----

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex11/listing.kt[]


Even the `Map` encoding of the set of possible choices feels overly specific, just like `List` was. `Map<A,Par<B>>` is used to provide a function, `(A) -> Par<B>`.


Let’s make a more general signature that unifies them all. We’ll call it `chooser` and allow it to perform selection through a function `(A) -> Par<B>`.

[source, kotlin]
----
fun <A, B> chooser(pa: Par<A>, choices: (A) -> Par<B>): Par<B> =
----

Implement this new primitive `chooser`, and then use it to implement `choice`, `choiceN`, and `choiceMap`.

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex12/listing.kt[]


`chooser` is perhaps no longer the most appropriate name for this operation, which is actually quite general—it’s a parallel computation that, when invoked, runs an initial computation whose result is used to determine a second computation.

Nothing says that this second computation even needs to exist before the first computation’s result is available. It doesn’t even need to be stored in a container like List or Map. This function, which comes up often in functional libraries, is usually called `bind` or `flatMap`:

[source, kotlin]
----
fun <A, B> flatMap(pa: Par<A>, f: (A) -> Par<B>): Par<B>
----


Is `flatMap` really the most primitive possible function, or can we generalize it yet further?

The name _flatMap_ is suggestive of the fact that this operation could be decomposed into two steps: _mapping_ `f: (A) -> Par<B>` over our `Par[A]`, which generates a `Par<Par<B>>`, and _flattening_ this nested `Par<Par<B>>` to a `Par<B>`.


Here is the interesting part: it suggests that all we need to do is add an even simpler combinator, let’s call it *join*, to convert a `Par<Par<X>>` to `Par<X>` for any choice of `X`.

Again, we’re simply following the types. We have an example that demands a function with a given signature, so we just bring it into existence. Now that it exists, we can think about what the signature means.

We call it join since, conceptually, it’s a parallel computation that, when run, will execute the inner computation, wait for it to finish (much like `Thread.join`), and then return its result.



Implement `join`. Can you see how to implement `flatMap` using `join`? And can you implement `join` using `flatMap`?

[source, kotlin]
----
fun <A> join(a: Par<Par<A>>): Par<A> =
----

IMPORTANT: xref:../../../test/kotlin/chapter7/exercises/ex13/listing.kt[]


> As you practice more functional programming, one of the skills you’ll develop is the ability to recognize what functions are expressible from an algebra and what the limitations of that algebra are. For instance, in the preceding example, it may not have been evident at first that a function like `choice` couldn’t be expressed purely in terms of `map`, `map2`, and `unit`. It also may not have been evident that choice was just a particular case of `flatMap`. Over time, observations like this will come more quickly. You’ll also get better at spotting how to modify your algebra to make some required combinator expressible. These abilities will be helpful for all of your API design work.

d[]


